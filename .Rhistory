admission_test <- data.frame(admission_test, admission_model=odds/(odds+1))
admission_test$prediction[admission_test$admission_model > 0.5] <- "Accepted"
admission_test$prediction[admission_test$admission_model <= 0.5] <- "Rejected"
# Accuracy Evaluation of nn model with a confusion matrix
cm <- table(admission_test$decision, admission_test$prediction)
cat("\nConfusion matrix for resulting nn model is: \n")
print(cm)
# Bring in new data:
admission_test <- adm_data[501:800, ]
table(admission_test$decision)
table(admission_test$status)
hist(admission_test$gretot)
odds <- exp(predict(adm_mod, admission_test))
admission_test <- data.frame(admission_test, admission_model=odds/(odds+1))
admission_test$prediction[admission_test$admission_model > 0.5] <- "Accepted"
admission_test$prediction[admission_test$admission_model <= 0.5] <- "Rejected"
# Accuracy Evaluation of nn model with a confusion matrix
cm <- table(admission_test$decision, admission_test$prediction)
cat("\nConfusion matrix for resulting nn model is: \n")
print(cm)
precision <- 114 / (114 + 62)
recall <- 114 / (114 + 36)
# Bring in new data:
admission_test <- adm_data[501:800, ]
table(admission_test$decision)
table(admission_test$status)
hist(admission_test$gretot)
odds <- exp(predict(adm_mod, admission_test))
admission_test <- data.frame(admission_test, admission_model=odds/(odds+1))
admission_test$prediction[admission_test$admission_model > 0.6] <- "Accepted"
admission_test$prediction[admission_test$admission_model <= 0.4] <- "Rejected"
# Accuracy Evaluation of nn model with a confusion matrix
cm <- table(admission_test$decision, admission_test$prediction)
cat("\nConfusion matrix for resulting nn model is: \n")
print(cm)
# Bring in new data:
admission_test <- adm_data[501:800, ]
table(admission_test$decision)
table(admission_test$status)
hist(admission_test$gretot)
odds <- exp(predict(adm_mod, admission_test))
admission_test <- data.frame(admission_test, admission_model=odds/(odds+1))
admission_test$prediction[admission_test$admission_model > 0.6] <- "Accepted"
admission_test$prediction[admission_test$admission_model <= 0.4] <- "Rejected"
# Accuracy Evaluation of nn model with a confusion matrix
cm <- table(admission_test$decision, admission_test$prediction)
cat("\nConfusion matrix for resulting nn model is: \n")
print(cm)
View(admission_test)
View(admission_test)
# Bring in new data:
admission_test <- adm_data[501:800, ]
table(admission_test$decision)
table(admission_test$status)
hist(admission_test$gretot)
odds <- exp(predict(adm_mod, admission_test))
admission_test <- data.frame(admission_test, admission_model=odds/(odds+1))
admission_test$prediction[admission_test$admission_model > 0.6] <- "Accepted"
admission_test$prediction[admission_test$admission_model <= 0.6] <- "Rejected"
# Accuracy Evaluation of nn model with a confusion matrix
cm <- table(admission_test$decision, admission_test$prediction)
cat("\nConfusion matrix for resulting nn model is: \n")
print(cm)
# Accuracy
accuracy <- length(admission_test$prediction == admission_test$admission_model) / length(admission_test$prediction)
# Accuracy
accuracy <- length(admission_test$prediction == admission_test$decision) / length(admission_test$prediction)
admission_test$prediction == admission_test$decision
# Accuracy
accuracy <- length((admission_test$prediction == admission_test$decision) == TRUE) / length(admission_test$prediction)
(admission_test$prediction == admission_test$decision) == TRUE
count(admission_test$prediction == admission_test$decision)
count(admission_test$prediction == admission_test$decision, TRUE)
count
count(admission_test$prediction == admission_test$decision, vars=TRUE)
count(admission_test$prediction == admission_test$decision, vars="TRUE")
sum(admission_test$prediction == admission_test$decision)
# Accuracy
accuracy <- sum(admission_test$prediction == admission_test$decision) / length(admission_test$prediction)
# Bring in new data:
admission_test <- adm_data[501:700, ]
table(admission_test$decision)
table(admission_test$status)
hist(admission_test$gretot)
odds <- exp(predict(adm_mod, admission_test))
admission_test <- data.frame(admission_test, admission_model=odds/(odds+1))
admission_test$prediction[admission_test$admission_model > 0.5] <- "Accepted"
admission_test$prediction[admission_test$admission_model <= 0.5] <- "Rejected"
# Accuracy
accuracy <- sum(admission_test$prediction == admission_test$decision) / length(admission_test$prediction)
# Bring in new data:
admission_test <- adm_data[501:600, ]
table(admission_test$decision)
table(admission_test$status)
hist(admission_test$gretot)
odds <- exp(predict(adm_mod, admission_test))
admission_test <- data.frame(admission_test, admission_model=odds/(odds+1))
admission_test$prediction[admission_test$admission_model > 0.5] <- "Accepted"
admission_test$prediction[admission_test$admission_model <= 0.5] <- "Rejected"
# Accuracy
accuracy <- sum(admission_test$prediction == admission_test$decision) / length(admission_test$prediction)
# Accuracy Evaluation of nn model with a confusion matrix
cm <- table(admission_test$decision, admission_test$prediction)
cat("\nConfusion matrix for resulting nn model is: \n")
print(cm)
recall <- 45 / (45 + 8)
precision <- 45 / (45 + 21)
recall <- 45 / (45 + 8)
F1_nn <- 2 * (precision*recall) / (precision + recall)
library(nnet)
# Set Sample Indices
set.seed(1)
sampidx <- c(sample(1:5860,4102))
nn_data <- data.frame(adm_data$gpafin, adm_data$grev, adm_data$grem, adm_data$grew, adm_data$status,
adm_data$degree, adm_data$ranking, adm_data$decision)
names(nn_data) <- c("gpafin", "grev", "grem", "grew", "status", "degree", "ranking", "decision")
# create and train Neural Network
cat("\nCreating and training a neural network . . \n")
adm_nn <- nnet(decision ~ gpafin + grev + grem + grew + status + degree + ranking, data=nn_data, subset = sampidx,
size=70)
# Accuracy Evaluation of nn model with a confusion matrix
cm <- table(nn_data$decision[-sampidx], predict(adm_nn, nn_data[-sampidx, ],
type="class"))
cat("\nConfusion matrix for resulting nn model is: \n")
print(cm)
precision_nn <- 640 / (640 + 306)
recall_nn <- 640 / (640 + 309)
F1_nn <- 2 * (precision_nn*recall_nn) / (precision_nn + recall_nn)
accuracy_nn <- (633 + 513) / length(nn_data$decision[-sampidx])
accuracy_nn <- (640 + 503) / length(nn_data$decision[-sampidx])
# Look at ranges...
summary(g_admission)
# Predict Status
mns <- summary(lsmeans(adm_mod, "status", type="response"))
# Graph Status
library(ggplot2)
ggplot(mns, aes(x=status, y=prob)) +
geom_bar(stat="identity") +
geom_errorbar(aes(ymin=asymp.LCL, ymax=asymp.UCL), width=0.2) +
theme_bw()
# Predict GPA
library(lsmeans)
adm_mns_gpa <- summary(lsmeans(adm_mod, "gpafin",
at=list(gpafin = seq(2, 4, 0.1)), type="response"))
# Graph GPA
g <- simpleScatter(g_admission, gpafin, decision_bin, title="Probability of Admission v. GPA",
xlab="GPA", ylab="P(Admission)")
g +
geom_line(data=adm_mns_gpa, aes(x=gpafin, y=prob), color="red") +
geom_line(data=adm_mns_gpa, aes(x=gpafin, y=asymp.LCL), linetype="dashed") +
geom_line(data=adm_mns_gpa, aes(x=gpafin, y=asymp.UCL), linetype="dashed")
# Predict GRE Verbal
adm_mns_grev <- summary(lsmeans(adm_mod, "grev",
at=list(grev = seq(135, 170, 1)), type="response"))
# Graph GRE Verbal
g1 <- simpleScatter(g_admission, grev, decision_bin, title="Probability of Admission v. GRE Verbal Score",
xlab="GRE Verbal", ylab="P(Admission)")
g1 +
geom_line(data=adm_mns_grev, aes(x=grev, y=prob), color="red") +
geom_line(data=adm_mns_grev, aes(x=grev, y=asymp.LCL), linetype="dashed") +
geom_line(data=adm_mns_grev, aes(x=grev, y=asymp.UCL), linetype="dashed")
# Predict GRE Math
adm_mns_grem <- summary(lsmeans(adm_mod, "grem",
at=list(grem = seq(141, 170, 1)), type="response"))
# Graph GRE Math
g2 <- simpleScatter(g_admission, grem, decision_bin, title="Probability of Admission v. GRE Math Score",
xlab="GRE Verbal", ylab="P(Admission)")
g2 +
geom_line(data=adm_mns_grem, aes(x=grem, y=prob), color="red") +
geom_line(data=adm_mns_grem, aes(x=grem, y=asymp.LCL), linetype="dashed") +
geom_line(data=adm_mns_grem, aes(x=grem, y=asymp.UCL), linetype="dashed")
# Predict Ranking
adm_mns_rank <- summary(lsmeans(adm_mod, "ranking",
at=list(ranking=seq(2.2, 5, 0.1)), type="response"))
# Graph Ranking
g3 <- simpleScatter(g_admission, ranking, decision_bin, title="Probability of Admission v. School Ranking",
xlab="Ranking", ylab="P(Admission)")
g3 +
geom_line(data=adm_mns_rank, aes(x=ranking, y=prob), color="red") +
geom_line(data=adm_mns_rank, aes(x=ranking, y=asymp.LCL), linetype="dashed") +
geom_line(data=adm_mns_rank, aes(x=ranking, y=asymp.UCL), linetype="dashed")
# Import data
adm_data <- read.csv("data/cs_data.csv", stringsAsFactors = FALSE)
# Add new column with binary decision values (0/1)
adm_data$decision_bin <- NA
adm_data$decision_bin[adm_data$decision == "Rejected"] <- 0
adm_data$decision_bin[adm_data$decision == "Accepted"] <- 1
# Factorize Variables
table(adm_data$decision)
adm_data$decision <- factor(adm_data$decision, levels=c("Rejected","Accepted"))
table(adm_data$status)
adm_data$status <- factor(adm_data$status, levels=c("A", "U", "I"))
table(adm_data$degree)
adm_data$degree <- factor(adm_data$degree, levels=c("Masters", "PhD"))
admission <- adm_data[1:500, ]
names(admission)
# Summary
summary(admission)
# Data distribution check
count(admission$degree)
hist(admission$ranking)
hist(admission$year)
hist(admission$gpafin)
hist(admission$gretot)
# Intital Model
adm_mod_0 <- glm(decision ~ gpafin + grev + grem + grew + status + degree + ranking + ranking*gpafin, data=admission, family="binomial")
summary(adm_mod_0)
# Intital Model
adm_mod_0 <- glm(decision ~ gpafin + grev + grem + grew + status + degree + ranking + ranking*gretot, data=admission, family="binomial")
summary(adm_mod_0)
# Intital Model
adm_mod_0 <- glm(decision ~ gpafin + gretot + grew +  status + degree + ranking + ranking*gretot, data=admission, family="binomial")
summary(adm_mod_0)
library(SDSRegressionR)
#Bring in data
coh <- read.csv("../../data/posterData.csv", stringsAsFactors=FALSE)
library(SDSRegressionR)
# Import data
adm_data <- read.csv("data/cs_data.csv", stringsAsFactors = FALSE)
# Add new column with binary decision values (0/1)
adm_data$decision_bin <- NA
adm_data$decision_bin[adm_data$decision == "Rejected"] <- 0
adm_data$decision_bin[adm_data$decision == "Accepted"] <- 1
# Factorize Variables
table(adm_data$decision)
adm_data$decision <- factor(adm_data$decision, levels=c("Rejected","Accepted"))
table(adm_data$status)
adm_data$status <- factor(adm_data$status, levels=c("A", "U", "I"))
table(adm_data$degree)
adm_data$degree <- factor(adm_data$degree, levels=c("Masters", "PhD"))
admission <- adm_data[1:500, ]
names(admission)
# Summary
summary(admission)
# Data distribution check
count(admission$degree)
hist(admission$ranking)
hist(admission$year)
hist(admission$gpafin)
hist(admission$gretot)
# Intital Model
adm_mod_0 <- glm(decision ~ gpafin + grev + grem + grew + status + degree + ranking + gpafin * status, data=admission, family="binomial")
summary(adm_mod_0)
# Assumption Check
library(car)
vif(adm_mod_0)
cooksPlot(adm_mod_0, key.variable = "id", print.obs = TRUE, sort.obs = TRUE)
threeOuts(adm_mod_0, key.variable = "id")
# Remove outliers
"%not in%" <- Negate("%in%")
g_admission <- admission[admission$id %not in% c('77'),]
# Re-run
adm_mod <- glm(decision ~ gpafin + grev + grem + grew + status + degree + ranking + gpafin * status, data=g_admission, family="binomial")
summary(adm_mod)
exp(adm_mod$coef)
exp(confint.default(adm_mod))
# Stats
library(rms)
adm_mod_2 <- lrm(decision ~ gpafin + grev + grem + grew + status + degree + ranking, gpafin * status, g_admission)
adm_mod_2
adm_mod_2 <- lrm(decision ~ gpafin + grev + grem + grew + status + degree + ranking + gpafin * status, g_admission)
adm_mod_2
# Pseudo R2
library(DescTools)
PseudoR2(adm_mod, which = "Nagelkerke")
# Test the full categorical variable
library(car)
Anova(adm_mod, type="III")
# Post-hoc testing
library(lsmeans)
lsmeans(adm_mod, "status", type="response")
pairs(lsmeans(adm_mod, "status"), reverse=TRUE, adjust="none")
summary(adm_mod)
ref.grid(adm_mod)
# Moderation
lmDecomp(adm_mod, "statusU", "gpafin", mod.type=2, mod.values = c(1, 2, 3), print.sslopes = FALSE)
# Moderation
lmDecomp(adm_mod, "statusA", "gpafin", mod.type=2, mod.values = c(1, 2, 3), print.sslopes = FALSE)
library(SDSRegressionR)
# Import data
adm_data <- read.csv("data/cs_data.csv", stringsAsFactors = FALSE)
# Add new column with binary decision values (0/1)
adm_data$decision_bin <- NA
adm_data$decision_bin[adm_data$decision == "Rejected"] <- 0
adm_data$decision_bin[adm_data$decision == "Accepted"] <- 1
# Factorize Variables
table(adm_data$decision)
adm_data$decision <- factor(adm_data$decision, levels=c("Rejected","Accepted"))
table(adm_data$status)
adm_data$status <- factor(adm_data$status, levels=c("A", "U", "I"))
table(adm_data$degree)
adm_data$degree <- factor(adm_data$degree, levels=c("Masters", "PhD"))
admission <- adm_data[1:500, ]
names(admission)
# Summary
summary(admission)
# Data distribution check
count(admission$degree)
hist(admission$ranking)
hist(admission$year)
hist(admission$gpafin)
hist(admission$gretot)
# Intital Model
adm_mod_0 <- glm(decision ~ gpafin + grev + grem + grew + status + degree + ranking, data=admission, family="binomial")
summary(adm_mod_0)
# Assumption Check
library(car)
vif(adm_mod_0)
cooksPlot(adm_mod_0, key.variable = "id", print.obs = TRUE, sort.obs = TRUE)
threeOuts(adm_mod_0, key.variable = "id")
# Remove outliers
"%not in%" <- Negate("%in%")
g_admission <- admission[admission$id %not in% c('77'),]
# Re-run
adm_mod <- glm(decision ~ gpafin + grev + grem + grew + status + degree + ranking, data=g_admission, family="binomial")
summary(adm_mod)
exp(adm_mod$coef)
exp(confint.default(adm_mod))
exp(adm_mod$coef)
OddsRatio(adm_mod)
odds.ration(adm_mod)
odds.ratio(adm_mod)
install.packages("oddsratio")
library("oddsratio", lib.loc="/Library/Frameworks/R.framework/Versions/3.4/Resources/library")
or_glm(data=g_admission, adm_model, 1, CI = 0.95)
or_glm(data=g_admission, adm_mod, 1, CI = 0.95)
or_glm(data=g_admission, adm_mod, incr = list(grev = 380, gpafin = 5), CI = 0.95)
or_glm(data=g_admission, adm_mod, incr = list(grev = 10, gpafin = 5), CI = 0.95)
incr = list(gpafin=1, grev=1, grem=1, grew=1, status=1, degree=1, ranking=1)
incr <- list(gpafin=1, grev=1, grem=1, grew=1, status=1, degree=1, ranking=1)
or_glm(data=g_admission, adm_mod, incr = , CI = 0.95)
incr <- list(gpafin=1, grev=1, grem=1, grew=1, status=1, degree=1, ranking=1)
or_glm(data=g_admission, adm_mod, incr=incr , CI = 0.95)
exp(adm_mod$coef)
exp(confint.default(adm_mod))
incr <- list(gpafin=.5, grev=10, grem=10, grew=.5, status=1, degree=1, ranking=.5)
or_glm(data=g_admission, adm_mod, incr=incr , CI = 0.95)
incr <- list(gpafin=.5, grev=20, grem=20, grew=.5, status=1, degree=1, ranking=.5)
or_glm(data=g_admission, adm_mod, incr=incr , CI = 0.95)
library(SDSRegressionR)
# Import data
adm_data <- read.csv("data/cs_data.csv", stringsAsFactors = FALSE)
# Add new column with binary decision values (0/1)
adm_data$decision_bin <- NA
adm_data$decision_bin[adm_data$decision == "Rejected"] <- 0
adm_data$decision_bin[adm_data$decision == "Accepted"] <- 1
# Factorize Variables
table(adm_data$decision)
adm_data$decision <- factor(adm_data$decision, levels=c("Rejected","Accepted"))
table(adm_data$status)
adm_data$status <- factor(adm_data$status, levels=c("A", "U", "I"))
table(adm_data$degree)
adm_data$degree <- factor(adm_data$degree, levels=c("Masters", "PhD"))
admission <- adm_data[1:500, ]
names(admission)
# Summary
summary(admission)
# Data distribution check
count(admission$degree)
hist(admission$ranking)
hist(admission$year)
hist(admission$gpafin)
hist(admission$gretot)
# Intital Model
adm_mod_0 <- glm(decision ~ gpafin + grev + grem + grew + status + degree + ranking, data=admission, family="binomial")
summary(adm_mod_0)
# Assumption Check
library(car)
vif(adm_mod_0)
cooksPlot(adm_mod_0, key.variable = "id", print.obs = TRUE, sort.obs = TRUE)
threeOuts(adm_mod_0, key.variable = "id")
# Remove outliers
"%not in%" <- Negate("%in%")
g_admission <- admission[admission$id %not in% c('77'),]
# Re-run
adm_mod <- glm(decision ~ gpafin + grev + grem + grew + status + degree + ranking, data=g_admission, family="binomial")
summary(adm_mod)
# # # # # # # #
# Odds-ratios #
# # # # # # # #
library(oddsratio)
incr <- list(gpafin=.5, grev=20, grem=20, grew=.5, status=1, degree=1, ranking=.5)
or_glm(data=g_admission, adm_mod, incr=incr , CI = 0.95)
# exp(adm_mod$coef)
# exp(confint.default(adm_mod))
# Stats
library(rms)
adm_mod_2 <- lrm(decision ~ gpafin + grev + grem + grew + status + degree + ranking, g_admission)
adm_mod_2
# Pseudo R2
library(DescTools)
PseudoR2(adm_mod, which = "Nagelkerke")
# Test the full categorical variable
library(car)
Anova(adm_mod, type="III")
# Post-hoc testing
library(lsmeans)
lsmeans(adm_mod, "status", type="response")
pairs(lsmeans(adm_mod, "status"), reverse=TRUE, adjust="none")
summary(adm_mod)
ref.grid(adm_mod)
# # PSA
# alpha_PSA <- -5.373861
# beta_PSA  <- 0.032964
# omega_PSA <- (-0.027747 * 66.145) + (-0.014582 * 16.264) + (1.025764 * 6.3669)
# vmark_PSA <- (log(0.50 / (1 - 0.50)) - alpha_PSA - omega_PSA) / beta_PSA
# vmark_PSA
#
# # GLEASON
# alpha_G <- -5.373861
# beta_G <- 1.025764
# omega_G <- (-0.027747 * 66.145) + (-0.014582 * 16.264) + (0.032964 * 15.377)
# vmark_G <- (log(0.50 / (1 - 0.50)) - alpha_G - omega_G) / beta_G
# vmark_G
# # # # # # # #
# Prediction  #
# # # # # # # #
# Bring in new data:
admission_test <- adm_data[501:600, ]
table(admission_test$decision)
table(admission_test$status)
hist(admission_test$gretot)
odds <- exp(predict(adm_mod, admission_test))
admission_test <- data.frame(admission_test, admission_model=odds/(odds+1))
admission_test$prediction[admission_test$admission_model > 0.5] <- "Accepted"
admission_test$prediction[admission_test$admission_model <= 0.5] <- "Rejected"
# Accuracy
accuracy <- sum(admission_test$prediction == admission_test$decision) / length(admission_test$prediction)
# Accuracy Evaluation of nn model with a confusion matrix
cm <- table(admission_test$decision, admission_test$prediction)
cat("\nConfusion matrix for resulting nn model is: \n")
print(cm)
precision <- 45 / (45 + 21)
recall <- 45 / (45 + 8)
F1_nn <- 2 * (precision*recall) / (precision + recall)
# # # # # # # #
# Neural Net  #
# # # # # # # #
library(nnet)
# Set Sample Indices
set.seed(1)
sampidx <- c(sample(1:5860,4102))
nn_data <- data.frame(adm_data$gpafin, adm_data$grev, adm_data$grem, adm_data$grew, adm_data$status,
adm_data$degree, adm_data$ranking, adm_data$decision)
names(nn_data) <- c("gpafin", "grev", "grem", "grew", "status", "degree", "ranking", "decision")
# create and train Neural Network
cat("\nCreating and training a neural network . . \n")
adm_nn <- nnet(decision ~ gpafin + grev + grem + grew + status + degree + ranking, data=nn_data, subset = sampidx,
size=70)
# Accuracy Evaluation of nn model with a confusion matrix
cm <- table(nn_data$decision[-sampidx], predict(adm_nn, nn_data[-sampidx, ],
type="class"))
cat("\nConfusion matrix for resulting nn model is: \n")
print(cm)
precision_nn <- 640 / (640 + 306)
recall_nn <- 640 / (640 + 309)
F1_nn <- 2 * (precision_nn*recall_nn) / (precision_nn + recall_nn)
accuracy_nn <- (640 + 503) / length(nn_data$decision[-sampidx])
# # # # #
# Plots #
# # # # #
# Look at ranges...
summary(g_admission)
# Predict Status
mns <- summary(lsmeans(adm_mod, "status", type="response"))
# Graph Status
library(ggplot2)
ggplot(mns, aes(x=status, y=prob)) +
geom_bar(stat="identity") +
geom_errorbar(aes(ymin=asymp.LCL, ymax=asymp.UCL), width=0.2) +
theme_bw()
# Predict GPA
library(lsmeans)
adm_mns_gpa <- summary(lsmeans(adm_mod, "gpafin",
at=list(gpafin = seq(2, 4, 0.1)), type="response"))
# Graph GPA
g <- simpleScatter(g_admission, gpafin, decision_bin, title="Probability of Admission v. GPA",
xlab="GPA", ylab="P(Admission)")
g +
geom_line(data=adm_mns_gpa, aes(x=gpafin, y=prob), color="red") +
geom_line(data=adm_mns_gpa, aes(x=gpafin, y=asymp.LCL), linetype="dashed") +
geom_line(data=adm_mns_gpa, aes(x=gpafin, y=asymp.UCL), linetype="dashed")
# Predict GRE Verbal
adm_mns_grev <- summary(lsmeans(adm_mod, "grev",
at=list(grev = seq(135, 170, 1)), type="response"))
# Graph GRE Verbal
g1 <- simpleScatter(g_admission, grev, decision_bin, title="Probability of Admission v. GRE Verbal Score",
xlab="GRE Verbal", ylab="P(Admission)")
g1 +
geom_line(data=adm_mns_grev, aes(x=grev, y=prob), color="red") +
geom_line(data=adm_mns_grev, aes(x=grev, y=asymp.LCL), linetype="dashed") +
geom_line(data=adm_mns_grev, aes(x=grev, y=asymp.UCL), linetype="dashed")
# Predict GRE Math
adm_mns_grem <- summary(lsmeans(adm_mod, "grem",
at=list(grem = seq(141, 170, 1)), type="response"))
# Graph GRE Math
g2 <- simpleScatter(g_admission, grem, decision_bin, title="Probability of Admission v. GRE Math Score",
xlab="GRE Verbal", ylab="P(Admission)")
g2 +
geom_line(data=adm_mns_grem, aes(x=grem, y=prob), color="red") +
geom_line(data=adm_mns_grem, aes(x=grem, y=asymp.LCL), linetype="dashed") +
geom_line(data=adm_mns_grem, aes(x=grem, y=asymp.UCL), linetype="dashed")
# Predict Ranking
adm_mns_rank <- summary(lsmeans(adm_mod, "ranking",
at=list(ranking=seq(2.2, 5, 0.1)), type="response"))
# Graph Ranking
g3 <- simpleScatter(g_admission, ranking, decision_bin, title="Probability of Admission v. School Ranking",
xlab="Ranking", ylab="P(Admission)")
g3 +
geom_line(data=adm_mns_rank, aes(x=ranking, y=prob), color="red") +
geom_line(data=adm_mns_rank, aes(x=ranking, y=asymp.LCL), linetype="dashed") +
geom_line(data=adm_mns_rank, aes(x=ranking, y=asymp.UCL), linetype="dashed")
